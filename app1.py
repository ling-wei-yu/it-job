# ----------------------------------------------------------------------
# æ¯•ä¸šè®¾è®¡ï¼šåŸºäºPythonçš„ITè¡Œä¸šæ‹›è˜æ•°æ®å¯è§†åŒ–åˆ†æç³»ç»Ÿ

# ----------------------------------------------------------------------

# --- æ ¸å¿ƒåº“å¯¼å…¥ ---
import streamlit as st
import pandas as pd
import plotly.express as px
import os
import jieba
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import pydeck as pdk

# ======================================================================
#   (A) é¡µé¢åŸºç¡€è®¾ç½®ã€å…¨å±€å¸¸é‡ã€æ ¸å¿ƒå‡½æ•°å®šä¹‰
# ======================================================================
st.set_page_config(page_title="ITè¡Œä¸šæ‹›è˜æ•°æ®åˆ†æç³»ç»Ÿ", page_icon="ğŸ’¼", layout="wide")

# --- å…¨å±€å¸¸é‡ ---
CITY_TIER_MAP = {
    'åŒ—äº¬': 'ä¸€çº¿åŸå¸‚', 'ä¸Šæµ·': 'ä¸€çº¿åŸå¸‚', 'å¹¿å·': 'ä¸€çº¿åŸå¸‚', 'æ·±åœ³': 'ä¸€çº¿åŸå¸‚',
    'æˆéƒ½': 'æ–°ä¸€çº¿åŸå¸‚', 'æ­å·': 'æ–°ä¸€çº¿åŸå¸‚', 'é‡åº†': 'æ–°ä¸€çº¿åŸå¸‚', 'æ­¦æ±‰': 'æ–°ä¸€çº¿åŸå¸‚',
    'è‹å·': 'æ–°ä¸€çº¿åŸå¸‚', 'è¥¿å®‰': 'æ–°ä¸€çº¿åŸå¸‚', 'å—äº¬': 'æ–°ä¸€çº¿åŸå¸‚', 'é•¿æ²™': 'æ–°ä¸€çº¿åŸå¸‚',
    'å¤©æ´¥': 'æ–°ä¸€çº¿åŸå¸‚', 'éƒ‘å·': 'æ–°ä¸€çº¿åŸå¸‚', 'ä¸œè': 'æ–°ä¸€çº¿åŸå¸‚', 'é’å²›': 'æ–°ä¸€çº¿åŸå¸‚',
    'åˆè‚¥': 'æ–°ä¸€çº¿åŸå¸‚', 'ä½›å±±': 'æ–°ä¸€çº¿åŸå¸‚', 'å®æ³¢': 'æ–°ä¸€çº¿åŸå¸‚'
}
EXPERIENCE_ORDER = ['æ— ç»éªŒ/åº”å±Šç”Ÿ', '1å¹´ä»¥å†…', '1-3å¹´', '3-5å¹´', '5-10å¹´', '10å¹´ä»¥ä¸Š']
EXPERIENCE_LABEL_MAPPING = {0: 'æ— ç»éªŒ/åº”å±Šç”Ÿ', 1: '1å¹´ä»¥å†…', 2: '1-3å¹´', 3: '3-5å¹´', 4: '5-10å¹´', 5: '10å¹´ä»¥ä¸Š',
                            6: 'ä¸è¯¦'}
EDUCATION_ORDER = ['ä¸­ä¸“/ä¸­æŠ€', 'é«˜ä¸­', 'å¤§ä¸“', 'æœ¬ç§‘', 'ç¡•å£«', 'åšå£«']
COMPANY_SIZE_ORDER = ['å°‘äº15äºº', '15-50äºº', '50-150äºº', '150-500äºº', '500-1000äºº', '1000-5000äºº', '5000-10000äºº',
                      '10000äººä»¥ä¸Š', 'ä¸è¯¦']


# --- æ•°æ®åŠ è½½ä¸å‡†å¤‡å‡½æ•°  ---
@st.cache_data
def load_data(file_path):
    if not os.path.exists(file_path): st.error(f"é”™è¯¯: æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ '{file_path}'ã€‚"); return None
    df = pd.read_csv(file_path)
    df['åŸå¸‚ç­‰çº§'] = df['æ£€ç´¢åŸå¸‚'].map(CITY_TIER_MAP).fillna('å…¶ä»–åŸå¸‚')
    return df


@st.cache_data
def prepare_experience_data(_df, mode='overall',cache_key=None):
    """
    ä¸€ä¸ªé€šç”¨çš„å‡½æ•°ï¼Œç”¨äºå‡†å¤‡â€œç»éªŒå›æŠ¥ç‡â€åˆ†ææ‰€éœ€çš„æ•°æ®ã€‚
    é€šè¿‡ mode å‚æ•°ï¼Œå¯ä»¥ä¸ºä¸åŒç¾¤ä½“ï¼ˆæ€»ä½“ã€æœ¬ç§‘ã€æ ¸å¿ƒæœ¬ç§‘ï¼‰ç”Ÿæˆæ•°æ®ã€‚
    :param _df: è¾“å…¥çš„ã€ç»è¿‡ç­›é€‰çš„ DataFrameã€‚
    :param mode: å­—ç¬¦ä¸²ï¼Œåˆ†ææ¨¡å¼ã€‚å¯é€‰å€¼ä¸º 'overall', 'bachelor', 'core'ã€‚
    :return: ä¸¤ä¸ªDataFrameï¼Œåˆ†åˆ«ç”¨äºç»˜åˆ¶å¹³å‡å€¼å’Œä¸­ä½æ•°å›¾è¡¨ã€‚
    """
    if mode == 'bachelor':
        source_df = _df[_df['å­¦å†'] == 'æœ¬ç§‘'].copy()
    elif mode == 'core':
        bachelor_df = _df[_df['å­¦å†'] == 'æœ¬ç§‘'].copy()

        def remove_outliers(group):
            q1 = group['æœˆè–ª'].quantile(0.25)
            q3 = group['æœˆè–ª'].quantile(0.75)
            return group[(group['æœˆè–ª'] >= q1) & (group['æœˆè–ª'] <= q3)]

        bachelor_df_no_na = bachelor_df.dropna(subset=['ç»éªŒç­‰çº§'])
        source_df = bachelor_df_no_na.groupby('ç»éªŒç­‰çº§').apply(remove_outliers).reset_index(drop=True)
    else:  # é»˜è®¤ä¸º 'overall'
        source_df = _df.copy()

    analysis_df = source_df[source_df['åŸå¸‚ç­‰çº§'].isin(['ä¸€çº¿åŸå¸‚', 'æ–°ä¸€çº¿åŸå¸‚'])]
    ordered_exp_dtype = pd.CategoricalDtype(categories=EXPERIENCE_ORDER, ordered=True)

    # è®¡ç®—å¹³å‡å€¼
    mean_df = analysis_df.groupby(['åŸå¸‚ç­‰çº§', 'ç»éªŒç­‰çº§'])['æœˆè–ª'].mean().round(0).reset_index()
    mean_df['ç»éªŒæ ‡ç­¾'] = mean_df['ç»éªŒç­‰çº§'].map(EXPERIENCE_LABEL_MAPPING)
    mean_df['ç»éªŒæ ‡ç­¾'] = mean_df['ç»éªŒæ ‡ç­¾'].astype(ordered_exp_dtype)
    mean_df = mean_df.sort_values(by=['åŸå¸‚ç­‰çº§', 'ç»éªŒæ ‡ç­¾'])

    # è®¡ç®—ä¸­ä½æ•°
    median_df = analysis_df.groupby(['åŸå¸‚ç­‰çº§', 'ç»éªŒç­‰çº§'])['æœˆè–ª'].median().round(0).reset_index()
    median_df['ç»éªŒæ ‡ç­¾'] = median_df['ç»éªŒç­‰çº§'].map(EXPERIENCE_LABEL_MAPPING)
    median_df['ç»éªŒæ ‡ç­¾'] = median_df['ç»éªŒæ ‡ç­¾'].astype(ordered_exp_dtype)
    median_df = median_df.sort_values(by=['åŸå¸‚ç­‰çº§', 'ç»éªŒæ ‡ç­¾'])

    return mean_df, median_df


@st.cache_data
def prepare_education_data(_df,cache_key=None):
    """å‡†å¤‡â€œå­¦å†ä»·å€¼åˆ†æâ€æ‰€éœ€çš„æ•°æ®ã€‚"""
    edu_to_analyze = ['ä¸­ä¸“/ä¸­æŠ€', 'é«˜ä¸­', 'å¤§ä¸“', 'æœ¬ç§‘', 'ç¡•å£«', 'åšå£«']
    analysis_df = _df[_df['å­¦å†'].isin(edu_to_analyze)]
    edu_salary_median = analysis_df.groupby('å­¦å†')['æœˆè–ª'].median().round(0).reset_index()
    ordered_edu_dtype = pd.CategoricalDtype(categories=EDUCATION_ORDER, ordered=True)
    edu_salary_median['å­¦å†'] = edu_salary_median['å­¦å†'].astype(ordered_edu_dtype)
    edu_salary_median = edu_salary_median.sort_values(by='å­¦å†')
    return edu_salary_median


@st.cache_data
def prepare_category_data(_df,cache_key=None):
    """å‡†å¤‡â€œå²—ä½ç±»åˆ«åˆ†æâ€æ‰€éœ€çš„æ•°æ®ã€‚"""
    hot_jobs = _df.groupby('æ£€ç´¢äºŒçº§èŒä½ç±»åˆ«').size().reset_index(name='å²—ä½æ•°é‡')
    top_15_hot = hot_jobs.sort_values(by='å²—ä½æ•°é‡', ascending=False).head(15)
    high_salary_jobs = _df.groupby('æ£€ç´¢äºŒçº§èŒä½ç±»åˆ«')['æœˆè–ª'].agg(['median', 'size']).reset_index()
    high_salary_jobs.columns = ['æ£€ç´¢äºŒçº§èŒä½ç±»åˆ«', 'ä¸­ä½æ•°æœˆè–ª', 'å²—ä½æ•°é‡']
    significant_jobs = high_salary_jobs[high_salary_jobs['å²—ä½æ•°é‡'] >= 50]
    top_15_high = significant_jobs.sort_values(by='ä¸­ä½æ•°æœˆè–ª', ascending=False).head(15)
    return top_15_hot, top_15_high


def prepare_company_data(_df):
    # å‡†å¤‡â€œä¼ä¸šç”»åƒåˆ†æâ€æ‰€éœ€çš„æ•°æ®ã€‚

    # --- å…¬å¸è§„æ¨¡åˆ†æ ---
    size_analysis = _df.groupby('å…¬å¸è§„æ¨¡æ ‡ç­¾')['æœˆè–ª'].agg(['median', 'size']).round(0)
    size_analysis.columns = ['ä¸­ä½æ•°æœˆè–ª', 'å²—ä½æ•°é‡']

    # å› ä¸ºåœ¨æ•°æ®æ¸…æ´—æ—¶ï¼Œå·²ç»å°†'å…¬å¸è§„æ¨¡æ ‡ç­¾'å®šä¹‰ä¸ºæœ‰åºåˆ†ç±»ç±»å‹ï¼Œ
    # æ‰€ä»¥ sort_index() ä¼šè‡ªåŠ¨æŒ‰ç…§æœŸæœ›çš„é¡ºåºï¼ˆä»å°åˆ°å¤§ï¼‰è¿›è¡Œæ’åºã€‚
    size_analysis = size_analysis.sort_index()

    # å…¬å¸ç±»å‹åˆ†æ
    type_analysis = _df.groupby('å…¬å¸ç±»å‹æ ‡ç­¾')['æœˆè–ª'].agg(['median', 'size']).round(0)
    type_analysis.columns = ['ä¸­ä½æ•°æœˆè–ª', 'å²—ä½æ•°é‡']
    # ä¸ºäº†å›¾è¡¨ç¾è§‚ï¼Œè¿‡æ»¤æ‰æ ·æœ¬é‡è¿‡å°å’Œâ€œä¸è¯¦â€çš„ç±»åˆ«
    type_analysis = type_analysis[(type_analysis['å²—ä½æ•°é‡'] >= 50) & (type_analysis.index != 'ä¸è¯¦')]
    type_analysis = type_analysis.sort_values(by='ä¸­ä½æ•°æœˆè–ª', ascending=False)

    return size_analysis, type_analysis


# è¯äº‘æ¨¡å—å‡†å¤‡æ•°æ®
@st.cache_data
def generate_wordcloud_image(_df, column_name, use_stopwords=False,cache_key=None ):
    if column_name not in _df.columns: return None
    text = " ".join(item for item in _df[column_name].dropna())
    if not text.strip(): return None

    word_list = jieba.cut(text)

    if use_stopwords:
        stopwords = {...}  # æ‚¨çš„åœç”¨è¯åˆ—è¡¨
        filtered_words = [word for word in word_list if len(word) > 1 and word not in stopwords]
    else:
        filtered_words = [word for word in word_list if len(word) > 1]

    if not filtered_words: return None

    # æ£€æŸ¥å­—ä½“æ–‡ä»¶
    font_path = 'simhei.ttf'
    if not os.path.exists(font_path):
        st.error(f"é”™è¯¯: æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ '{font_path}'ã€‚")
        return None

    wordcloud = WordCloud(
        font_path=font_path, background_color="white", width=1000, height=500, max_words=100
    ).generate(" ".join(filtered_words))

    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis("off")
    return fig


# githubä¸Šä¼ æ•°æ®
@st.cache_data
def load_data_from_url(url):
    """ä»URLåŠ è½½å¹¶é¢„å¤„ç†æ•°æ®"""
    try:
        df = pd.read_csv(url, compression='zip')

        #  å»é™¤ "_x000D_"å­—ç¬¦
        # å¯¹æ‰€æœ‰æ–‡æœ¬ç±»å‹çš„åˆ—ï¼Œè¿›è¡Œä¸€æ¬¡æ€§æ›¿æ¢
        for col in df.select_dtypes(include=['object']).columns:
            df[col] = df[col].str.replace('_x000D_', '', regex=False)

        df['åŸå¸‚ç­‰çº§'] = df['æ£€ç´¢åŸå¸‚'].map(CITY_TIER_MAP).fillna('å…¶ä»–åŸå¸‚')
        return df
    except Exception as e:
        st.error(f"ä»URLåŠ è½½æ•°æ®æ—¶å‡ºé”™: {e}")
        return None


# ======================================================================
#   (B) UIä¸ä¸»é€»è¾‘
# ======================================================================

st.title("ğŸ“Š ITè¡Œä¸šæ‹›è˜æ•°æ®å¯è§†åŒ–åˆ†æç³»ç»Ÿ")

# å®šä¹‰ä»GitHubè·å–çš„åŸå§‹æ•°æ®æ–‡ä»¶URL (Raw URL)

DATA_URL = "https://github.com/ling-wei-yu/it-job/releases/download/V1.0/it_data_cleaned_v6_final.zip"

# è°ƒç”¨å‡½æ•°ä»URLåŠ è½½æ•°æ®
df = load_data_from_url(DATA_URL)

# æ£€æŸ¥æ•°æ®æ˜¯å¦åŠ è½½æˆåŠŸ
if df is None:
    st.warning("æ•°æ®åŠ è½½å¤±è´¥ï¼Œåº”ç”¨æ— æ³•ç»§ç»­ã€‚è¯·æ£€æŸ¥URLæ˜¯å¦æ­£ç¡®æˆ–ç½‘ç»œè¿æ¥ã€‚")
    st.stop()

# --- ä¾§è¾¹æ ç­›é€‰å™¨ ---
st.sidebar.header("ğŸ”¬ å…¨å±€ç­›é€‰å™¨")
selected_cities = st.sidebar.multiselect('é€‰æ‹©åŸå¸‚ (å¯å¤šé€‰)', options=sorted(df['æ£€ç´¢åŸå¸‚'].unique()), default=[])
selected_education = st.sidebar.multiselect('é€‰æ‹©å­¦å† (å¯å¤šé€‰)', options=sorted(df['å­¦å†'].unique()), default=[])
selected_experience = st.sidebar.multiselect('é€‰æ‹©å·¥ä½œç»éªŒ (å¯å¤šé€‰)', options=sorted(df['ç»éªŒæ ‡ç­¾'].unique()),
                                             default=[])

df_filtered = df.copy()
if selected_cities: df_filtered = df_filtered[df_filtered['æ£€ç´¢åŸå¸‚'].isin(selected_cities)]
if selected_education: df_filtered = df_filtered[df_filtered['å­¦å†'].isin(selected_education)]
if selected_experience: df_filtered = df_filtered[df_filtered['ç»éªŒæ ‡ç­¾'].isin(selected_experience)]

st.sidebar.write("---")
st.sidebar.metric(label="ç¬¦åˆæ¡ä»¶çš„å²—ä½æ€»æ•°", value=f"{len(df_filtered)}")
st.sidebar.info("ç»„åˆä½¿ç”¨ç­›é€‰å™¨ï¼Œæ‰€æœ‰å›¾è¡¨éƒ½å°†å®æ—¶æ›´æ–°ã€‚")

st.write("---")

# ======================================================================
#   (C) â€œåŒæ¨¡æ€â€æ™ºèƒ½æ¸²æŸ“é€»è¾‘
# ======================================================================
st.write("---")

# --- 1. å†³å®šç”¨äºå±•ç¤ºçš„æ•°æ® ---
is_filtered = bool(selected_cities or selected_education or selected_experience)

if is_filtered:
    df_display = df_filtered
else:
    df_display = df

# --- 2. "æ— æ•°æ®"çš„é˜²å¾¡æ€§æ£€æŸ¥ ---
if df_display.empty:
    st.warning("åœ¨æ­¤ç­›é€‰æ¡ä»¶ä¸‹ï¼Œæ²¡æœ‰æ‰¾åˆ°è¶³å¤Ÿçš„æ•°æ®ç”¨äºåˆ†æã€‚è¯·å°è¯•æ”¾å®½ç­›é€‰æ¡ä»¶ã€‚")

# --- 3. æ ¹æ®æ¨¡å¼ï¼Œæ¸²æŸ“ä¸åŒçš„UI ---
elif not is_filtered:
    # ---------------------------------
    #   æ¨¡å¼ä¸€ï¼šâ€œå®è§‚æ¦‚è§ˆâ€ (å½“æ— ç­›é€‰æ—¶)
    # ---------------------------------
    st.info(
        "â„¹ï¸ **æ‚¨æ­£åœ¨æŸ¥çœ‹ã€å®è§‚æ¦‚è§ˆã€‘ã€‚** è¿™é‡Œå±•ç¤ºçš„æ˜¯åŸºäº**å…¨éƒ¨æ•°æ®**çš„æ€»ä½“è¶‹åŠ¿ã€‚æ‚¨å¯ä»¥ä½¿ç”¨å·¦ä¾§çš„ç­›é€‰å™¨ï¼Œå¯¹ç‰¹å®šç¾¤ä½“è¿›è¡Œæ·±åº¦ä¸‹é’»åˆ†æã€‚")

    # --- æ¨¡å—ä¸€ï¼šç»éªŒå›æŠ¥ç‡ ---
    st.header("1. ç»éªŒå›æŠ¥ç‡åˆ†æï¼šå¤šç¾¤ä½“å¯¹æ¯”")
    tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ æ€»ä½“è¶‹åŠ¿åˆ†æ", "ğŸ“ æœ¬ç§‘ç”Ÿä¸“å±åˆ†æ", "ğŸ¯ æ ¸å¿ƒæœ¬ç§‘ç”Ÿåˆ†æ"])
    with tab1:
        st.subheader("å…¨é‡æ•°æ®ï¼šå¹³å‡å€¼ vs. ä¸­ä½æ•°")
        mean_data, median_data = prepare_experience_data(df_display, mode='overall')
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("###### å¹³å‡è–ªèµ„å¢é•¿æ›²çº¿")
            fig_mean = px.line(mean_data, x='ç»éªŒæ ‡ç­¾', y='æœˆè–ª', color='åŸå¸‚ç­‰çº§', markers=True,
                               title="å·¥ä½œç»éªŒå¯¹â€œå¹³å‡è–ªèµ„â€çš„å¢é•¿å›æŠ¥ç‡")
            fig_mean.update_layout(title_x=0.5, title_font_size=16);
            st.plotly_chart(fig_mean, use_container_width=True)
        with col2:
            st.markdown("###### ä¸­ä½æ•°è–ªèµ„å¢é•¿æ›²çº¿")
            fig_median = px.line(median_data, x='ç»éªŒæ ‡ç­¾', y='æœˆè–ª', color='åŸå¸‚ç­‰çº§', markers=True,
                                 title="å·¥ä½œç»éªŒå¯¹â€œä¸­ä½æ•°è–ªèµ„â€çš„å¢é•¿å›æŠ¥ç‡")
            fig_median.update_layout(title_x=0.5, title_font_size=16);
            st.plotly_chart(fig_median, use_container_width=True)
            # ç¬¬ä¸€çº§ï¼šæ ¸å¿ƒæ¦‚è¦
        st.markdown(
            "æ ¸å¿ƒç»“è®ºï¼šæ— è®ºæ˜¯å¹³å‡å€¼è¿˜æ˜¯ä¸­ä½æ•°ï¼Œä¸€çº¿åŸå¸‚çš„èµ·è–ªä¸ç»éªŒå›æŠ¥ç‡å‡é«˜äºæ–°ä¸€çº¿åŸå¸‚ã€‚åŒæ—¶ï¼Œå¹³å‡å€¼æ˜¾è‘—é«˜äºä¸­ä½æ•°ï¼Œæ­ç¤ºäº†è–ªé…¬çš„å³åæ€åˆ†å¸ƒã€‚")

        # ç¬¬äºŒçº§ï¼šå¯å±•å¼€çš„è¯¦ç»†è§£è¯»
        with st.expander("ç‚¹å‡»æŸ¥çœ‹è¯¦ç»†è§£è¯» ğŸ‘‡"):
            st.markdown("""
                *   **åŸå¸‚å·®å¼‚:** å¯¹æ¯”ä¸¤æ¡â€œä¸­ä½æ•°â€å¢é•¿æ›²çº¿ï¼Œä¸€çº¿åŸå¸‚çš„åº”å±Šç”Ÿèµ·è–ªï¼ˆçº¦10,000å…ƒï¼‰æ¯”æ–°ä¸€çº¿åŸå¸‚ï¼ˆçº¦8,500å…ƒï¼‰é«˜å‡ºçº¦17%ã€‚éšç€ç»éªŒå¢é•¿è‡³â€œ5-10å¹´â€ï¼Œè¿™ä¸€è–ªé…¬å·®è·è¢«è¿›ä¸€æ­¥æ‹‰å¤§ã€‚
                *   **ç»Ÿè®¡å­¦æ´å¯Ÿ:** â€œå¹³å‡è–ªèµ„â€æ›²çº¿å…¨ç¨‹æ˜¾è‘—é«˜äºâ€œä¸­ä½æ•°è–ªèµ„â€æ›²çº¿ï¼Œè¿™ç›´è§‚åœ°è¯æ˜äº†ITè¡Œä¸šè–ªé…¬çš„â€œå³åæ€â€åˆ†å¸ƒç‰¹å¾ã€‚è¿™æ„å‘³ç€ï¼Œå°‘æ•°è–ªé…¬æé«˜çš„â€œæ˜æ˜Ÿâ€å²—ä½ï¼Œå¯¹æ•´ä½“çš„å¹³å‡æ°´å¹³æœ‰å¼ºçƒˆçš„æ‹‰å‡æ•ˆåº”ã€‚å› æ­¤ï¼Œå¯¹äºæ™®é€šæ±‚èŒè€…ï¼Œä¸­ä½æ•°æ˜¯æ›´å…·å‚è€ƒä»·å€¼çš„åŸºå‡†ã€‚
                *   **æå‡ºç–‘é—®:** å³ä½¿æ˜¯ä¸­ä½æ•°ï¼Œåº”å±Šç”Ÿçš„èµ·è–ªä¹Ÿæ¥è¿‘ä¸‡å…ƒã€‚è¿™ä¸ªæ•°å­—æ˜¯å¦ä»ç„¶å—åˆ°äº†å°‘æ•°â€œå¤©æ‰â€æ¯•ä¸šç”Ÿçš„å½±å“ï¼Ÿä¸ºäº†å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å°†åœ¨ä¸‹ä¸€ä¸ªæ ‡ç­¾é¡µä¸­ï¼Œèšç„¦äºå æ¯”æœ€å¤§çš„â€œæœ¬ç§‘ç”Ÿâ€ç¾¤ä½“ã€‚
                """)
    with tab2:
        st.subheader("æœ¬ç§‘ç”Ÿç¾¤ä½“ï¼šæ›´å…·ä»£è¡¨æ€§çš„è–ªé…¬è½¨è¿¹")
        _, bachelor_median_data = prepare_experience_data(df_display, mode='bachelor')
        fig_bachelor = px.line(bachelor_median_data, x='ç»éªŒæ ‡ç­¾', y='æœˆè–ª', color='åŸå¸‚ç­‰çº§', markers=True,
                               title="æœ¬ç§‘ç”Ÿä¸“å±ï¼šå·¥ä½œç»éªŒå¯¹â€œä¸­ä½æ•°è–ªèµ„â€çš„å¢é•¿å›æŠ¥ç‡")
        fig_bachelor.update_layout(title_x=0.5, title_font_size=16);
        st.plotly_chart(fig_bachelor, use_container_width=True)
        st.info("""
                **åˆ†æç»“è®º:**
                *   **èšç„¦ä¸»ä½“:** æ­¤å›¾ä»…ç­›é€‰â€œæœ¬ç§‘å­¦å†â€çš„å²—ä½è¿›è¡Œåˆ†æï¼Œæ’é™¤äº†å…¶ä»–å­¦å†çš„å¹²æ‰°ï¼Œå…¶ç»“è®ºæ›´è´´è¿‘æ™®é€šæœ¬ç§‘æ¯•ä¸šç”Ÿçš„èŒä¸šå‘å±•è½¨è¿¹ã€‚
                *   **æå‡ºè¿›ä¸€æ­¥ç–‘é—®:** æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œæœ¬ç§‘åº”å±Šç”Ÿçš„ä¸­ä½æ•°èµ·è–ªï¼ˆçº¦8-9kï¼‰ç›¸è¾ƒäºæ€»ä½“å¸‚åœºçš„å¹³å‡è–ªèµ„ï¼ˆè¿‡ä¸‡ï¼‰æ›´ä¸ºè´´è¿‘ç°å®ã€‚**ç„¶è€Œï¼Œè¿™ä¸ªä¸­ä½æ•°æ˜¯å¦ä»ç„¶å—åˆ°äº†å°‘æ•°â€œå¤©æ‰æœ¬ç§‘ç”Ÿâ€é«˜è–ªå²—ä½çš„ç¦»ç¾¤å€¼å½±å“?**
                """)
    with tab3:
        st.subheader("æ ¸å¿ƒæœ¬ç§‘ç”Ÿç¾¤ä½“ï¼šå‰”é™¤ç¦»ç¾¤å€¼åçš„ç²¾ç»†åŒ–åˆ†æ")
        _, core_bachelor_data = prepare_experience_data(df_display, mode='core')
        fig_core = px.line(core_bachelor_data, x='ç»éªŒæ ‡ç­¾', y='æœˆè–ª', color='åŸå¸‚ç­‰çº§', markers=True,
                           title="æ ¸å¿ƒæœ¬ç§‘ç”Ÿ(è–ªèµ„25%-75%)ï¼šå¯¹â€œä¸­ä½æ•°è–ªèµ„â€çš„å›æŠ¥ç‡")
        fig_core.update_layout(title_x=0.5, title_font_size=16);
        st.plotly_chart(fig_core, use_container_width=True)
        st.info(
            """
            **æœ€ç»ˆåˆ†æ:**
            *   **æœ€ç»ˆåŸºå‡†:** æ­¤å›¾åœ¨â€œæœ¬ç§‘ç”Ÿâ€ç¾¤ä½“åŸºç¡€ä¸Šï¼Œè¿›ä¸€æ­¥å‰”é™¤äº†æ¯ä¸ªç»éªŒç­‰çº§ä¸­è–ªèµ„æœ€é«˜å’Œæœ€ä½çš„25%çš„ç¦»ç¾¤å€¼ï¼Œæ—¨åœ¨åæ˜ å¸‚åœºä¸­æœ€â€œ**æ™®é€šå¤§å¤šæ•°**â€çš„è–ªé…¬å˜åŒ–è¶‹åŠ¿ã€‚è¿™ä¸ºæ™®é€šæœ¬ç§‘ç”Ÿæä¾›äº†ä¸€ä¸ª**æœ€ä¿å®ˆã€ä¹Ÿæœ€å…·å‚è€ƒä»·å€¼**çš„è–ªé…¬æœŸæœ›åŸºå‡†ã€‚
            *   **æœ‰è¶£çš„å‘ç°:** åœ¨â€œæ— ç»éªŒ/åº”å±Šç”Ÿâ€é˜¶æ®µï¼Œæ ¸å¿ƒç¾¤ä½“çš„ä¸­ä½æ•°è–ªèµ„ç”šè‡³ç•¥é«˜äºå…¨ä½“æœ¬ç§‘ç”Ÿï¼Œè¿™æ­ç¤ºäº†åœ¨åº”å±Šç”Ÿå¸‚åœºï¼Œå­˜åœ¨å¤§é‡ä½è–ªå²—ä½ï¼Œå…¶å¯¹ä¸­ä½æ•°çš„â€œä¸‹æ‹‰â€æ•ˆåº”ä¸å®¹å¿½è§†ã€‚
            """
        )

    st.write("---")

    # --- æ¨¡å—äºŒï¼šå­¦å†ä»·å€¼ ---
    st.header("2. å­¦å†ä»·å€¼åˆ†æ")
    edu_data = prepare_education_data(df_display)
    fig_edu = px.bar(edu_data, x='å­¦å†', y='æœˆè–ª', text='æœˆè–ª', color='å­¦å†', template='plotly_white',
                     title="ä¸åŒå­¦å†å±‚æ¬¡çš„ITå²—ä½è–ªé…¬ä¸­ä½æ•°å¯¹æ¯”")
    fig_edu.update_layout(title_x=0.5, xaxis_title=None, yaxis_visible=False, showlegend=False,
                          yaxis_range=[0, edu_data['æœˆè–ª'].max() * 1.15 if not edu_data.empty else 10000])
    fig_edu.update_traces(texttemplate='%{y:,.0f} å…ƒ', textposition='outside');
    st.plotly_chart(fig_edu, use_container_width=True)
    # ç¬¬ä¸€çº§ï¼šæ ¸å¿ƒæ¦‚è¦
    st.markdown("æ ¸å¿ƒç»“è®ºï¼šå­¦å†æ°´å¹³ä¸è–ªé…¬ä¸­ä½æ•°å­˜åœ¨æ¸…æ™°çš„é˜¶æ¢¯æ•ˆåº”ï¼Œç ”ç©¶ç”ŸåŠä»¥ä¸Šæ•™è‚²å¸¦æ¥çš„è–ªé…¬è·ƒå‡å°¤ä¸ºæ˜¾è‘—ã€‚")

    # ç¬¬äºŒçº§ï¼šå¯å±•å¼€çš„è¯¦ç»†è§£è¯»
    with st.expander("ç‚¹å‡»æŸ¥çœ‹è¯¦ç»†è§£è¯» ğŸ‘‡"):
        st.markdown("""
        *   **é‡åŒ–é˜¶æ¢¯:** ä»â€œå¤§ä¸“â€çš„9,000å…ƒï¼Œåˆ°â€œåšå£«â€çš„30,000å…ƒï¼Œå›¾è¡¨æ¸…æ™°åœ°å±•ç¤ºäº†é«˜ç­‰æ•™è‚²åœ¨ITèŒåœºçš„ç›´æ¥é‡‘é’±å›æŠ¥ã€‚
        *   **â€œæœ¬ç¡•â€åˆ†æ°´å²­:** â€˜æœ¬ç§‘â€™å­¦å†çš„ä¸­ä½æ•°è–ªé…¬ï¼ˆ15,000å…ƒï¼‰æ˜¯è¿›å…¥ITè¡Œä¸šä¸»æµå²—ä½çš„â€œåŸºç¡€é—¨ç¥¨â€ã€‚è€Œä»â€œæœ¬ç§‘â€åˆ°â€œç¡•å£«â€ï¼ˆ17,500å…ƒï¼‰ï¼Œå†åˆ°â€œåšå£«â€ï¼ˆ30,000å…ƒï¼‰ï¼Œè–ªé…¬å®ç°äº†ä¸¤æ¬¡æ˜¾è‘—çš„ã€éçº¿æ€§çš„è·ƒå‡ï¼Œè¿™å‡¸æ˜¾äº†ç ”ç©¶ç”Ÿæ•™è‚²å¯¹äºå†²å‡»é«˜è–ªå²—ä½çš„å†³å®šæ€§ä½œç”¨ã€‚
        *   **ä¸€ä¸ªæœ‰è¶£çš„å‘ç°:** åœ¨æˆ‘ä»¬çš„æ•°æ®ä¸­ï¼Œâ€œæœ¬ç§‘â€ä¸â€œæœ¬ç§‘åŠä»¥ä¸Šâ€çš„è–ªé…¬ä¸­ä½æ•°å®Œå…¨ç›¸åŒï¼Œè¿™å¯èƒ½è¡¨æ˜åœ¨è–ªé…¬ä¸»ä½“ä¸Šï¼Œè¿™ä¸¤ä¸ªè¦æ±‚åœ¨å¸‚åœºä¸Šçš„å®šä½é«˜åº¦é‡åˆã€‚
        """)

    st.write("---")

    # --- æ¨¡å—ä¸‰ï¼šå²—ä½ç±»åˆ« ---
    st.header("3. å¸‚åœºçƒ­ç‚¹åˆ†æï¼šçƒ­é—¨ vs. é«˜è–ªå²—ä½ç±»åˆ«")

    hot_data, high_salary_data = prepare_category_data(df_display)
    col3, col4 = st.columns(2)

    with col3:
        st.subheader("çƒ­é—¨å²—ä½ TOP 15 (æŒ‰éœ€æ±‚é‡)")

        # ä½¿ç”¨â€œé“¾å¼è°ƒç”¨â€ï¼Œå®Œæˆæ‰€æœ‰é…ç½®
        fig_hot = (px.bar(
            hot_data, x='å²—ä½æ•°é‡', y='æ£€ç´¢äºŒçº§èŒä½ç±»åˆ«', text='å²—ä½æ•°é‡',
            orientation='h', template='plotly_white', title='ITè¡Œä¸šçƒ­é—¨å²—ä½ TOP 15',
            labels={'æ£€ç´¢äºŒçº§èŒä½ç±»åˆ«': 'èŒä½ç±»åˆ«'}  # é‡å‘½åTooltip
        ).update_layout(
            title_x=0.5, xaxis_title='å²—ä½æ•°é‡ (ä¸ª)', yaxis_title=None,
            yaxis={'categoryorder': 'total ascending'},
            margin=dict(l=150)  # å¢åŠ å·¦è¾¹è·
        ).update_traces(
            textposition='outside'
        ))
        st.plotly_chart(fig_hot, use_container_width=True)

    with col4:
        st.subheader("é«˜è–ªå²—ä½ TOP 15 (æŒ‰ä¸­ä½æ•°æœˆè–ª)")

        # ä½¿ç”¨â€œé“¾å¼è°ƒç”¨â€
        fig_high = (px.bar(
            high_salary_data, x='ä¸­ä½æ•°æœˆè–ª', y='æ£€ç´¢äºŒçº§èŒä½ç±»åˆ«', text='ä¸­ä½æ•°æœˆè–ª',
            orientation='h', template='plotly_white', title='ITè¡Œä¸šé«˜è–ªå²—ä½ TOP 15',
            labels={'æ£€ç´¢äºŒçº§èŒä½ç±»åˆ«': 'èŒä½ç±»åˆ«'}
        ).update_layout(
            title_x=0.5, xaxis_title='ä¸­ä½æ•°æœˆè–ª (å…ƒ)', yaxis_title="èŒä½ç±»åˆ«",
            yaxis={'categoryorder': 'total ascending'}
        ).update_traces(
            texttemplate='%{x:,.0f} å…ƒ',
            textposition='outside'
        ))
        st.plotly_chart(fig_high, use_container_width=True)

    # ç¬¬ä¸€çº§ï¼šæ ¸å¿ƒæ¦‚è¦
    st.markdown(
        "æ ¸å¿ƒç»“è®ºï¼šâ€œåç«¯å¼€å‘â€æ˜¯å¸‚åœºéœ€æ±‚æœ€å¹¿çš„å²—ä½ï¼Œè€Œâ€œäººå·¥æ™ºèƒ½â€åˆ™æ˜¯è–ªé…¬å›æŠ¥æœ€é«˜çš„é¢†åŸŸï¼Œæ­ç¤ºäº†â€œçƒ­é—¨â€ä¸â€œé«˜è–ªâ€çš„å·®å¼‚ã€‚")

    # ç¬¬äºŒçº§ï¼šå¯å±•å¼€çš„è¯¦ç»†è§£è¯»
    with st.expander("ç‚¹å‡»æŸ¥çœ‹è¯¦ç»†è§£è¯» ğŸ‘‡"):
        st.markdown("""
        *   **éœ€æ±‚ç«¯åˆ†æ (çƒ­é—¨æ¦œ):** `åç«¯å¼€å‘`ã€`æŠ€æœ¯ç®¡ç†`ã€`å‰ç«¯/ç§»åŠ¨å¼€å‘` å æ®äº†éœ€æ±‚é‡çš„å‰ä¸‰ç”²ï¼Œæ˜¯æ„æˆITè¡Œä¸šç”¨äººéœ€æ±‚çš„â€œåŸºæœ¬ç›˜â€ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œ`äººå·¥æ™ºèƒ½` çš„éœ€æ±‚é‡å·²è¶…è¿‡ `æµ‹è¯•`ï¼Œä½åˆ—ç¬¬å››ï¼Œæ˜¾ç¤ºäº†å…¶å¼ºåŠ²çš„å‘å±•åŠ¿å¤´ã€‚
        *   **ä»·å€¼ç«¯åˆ†æ (é«˜è–ªæ¦œ):** `äººå·¥æ™ºèƒ½` ä»¥è¶…è¿‡20,000å…ƒçš„ä¸­ä½æ•°æœˆè–ªï¼Œæ— å¯äº‰è®®åœ°æˆä¸ºâ€œè–ªé…¬ä¹‹ç‹â€ã€‚ç´§éšå…¶åçš„æ˜¯ `é«˜ç«¯æŠ€æœ¯èŒä½` å’Œ `æŠ€æœ¯ç®¡ç†`ï¼Œè¿™æ¸…æ™°åœ°æŒ‡æ˜äº†â€œç²¾æ·±æŠ€æœ¯â€ä¸â€œèµ°å‘ç®¡ç†â€æ˜¯ITä»ä¸šè€…çš„ä¸¤æ¡é»„é‡‘æ™‹å‡è·¯çº¿ã€‚
        *   **â€œé‡‘å­—å¡”â€ç»“æ„æ´å¯Ÿ:** `æµ‹è¯•`ã€`è¿ç»´/æŠ€æœ¯æ”¯æŒ` ç­‰å²—ä½åœ¨â€œçƒ­é—¨æ¦œâ€ä¸Šååˆ—å‰èŒ…ï¼Œä½†åœ¨â€œé«˜è–ªæ¦œâ€ä¸Šå´ä¸è§è¸ªå½±ã€‚è¿™æ­ç¤ºäº†ITè¡Œä¸šçš„â€œé‡‘å­—å¡”â€ç»“æ„ï¼šå¡”åŸºæ˜¯ä¿è¯è¡Œä¸šè¿è½¬ã€éœ€æ±‚é‡å¤§ä½†è–ªé…¬æ™®éçš„å²—ä½ï¼›å¡”å°–åˆ™æ˜¯æ¨åŠ¨è¡Œä¸šåˆ›æ–°ã€æŠ€æœ¯å£å’é«˜ä¸”è–ªé…¬ä¸°åšçš„å²—ä½ã€‚
        """)

    # æ¨¡å—å››ä¼ä¸šç”»åƒåˆ†æ
    st.header("4. ä¼ä¸šç”»åƒåˆ†æï¼šè§„æ¨¡ä¸æ€§è´¨çš„å¯¹æ¯”")
    size_data, type_data = prepare_company_data(df_filtered)

    col5, col6 = st.columns(2)

    with col5:
        st.subheader("ä¸åŒå…¬å¸è§„æ¨¡çš„è–ªé…¬å¯¹æ¯”")
        fig_size = px.bar(size_data, x=size_data.index, y='ä¸­ä½æ•°æœˆè–ª', text='ä¸­ä½æ•°æœˆè–ª',
                          title='å…¬å¸è§„æ¨¡ vs. è–ªé…¬ä¸­ä½æ•°')
        fig_size.update_layout(title_x=0.5, xaxis_title=None)
        fig_size.update_traces(texttemplate='%{y:,.0f} å…ƒ', textposition='outside')
        if not size_data.empty:
            fig_size.update_yaxes(range=[0, size_data['ä¸­ä½æ•°æœˆè–ª'].max() * 1.15])
        st.plotly_chart(fig_size, use_container_width=True)

    with col6:
        st.subheader("ä¸åŒå…¬å¸æ€§è´¨çš„è–ªé…¬å¯¹æ¯”")
        fig_type = px.bar(type_data, x=type_data.index, y='ä¸­ä½æ•°æœˆè–ª', text='ä¸­ä½æ•°æœˆè–ª',
                          title='å…¬å¸æ€§è´¨ vs. è–ªé…¬ä¸­ä½æ•°')
        # æ ¸å¿ƒä¿®æ­£ï¼šå¢åŠ å·¦è¾¹è·(l=120)ï¼Œä¸ºYè½´æ ‡ç­¾ç•™å‡ºè¶³å¤Ÿç©ºé—´
        fig_type.update_layout(title_x=0.5, xaxis_title=None, margin=dict(l=120))
        fig_type.update_traces(texttemplate='%{y:,.0f} å…ƒ', textposition='outside')
        # ä¸ºYè½´èŒƒå›´å¢åŠ ä¸€äº›é¡¶éƒ¨ç©ºé—´
        if not type_data.empty:
            fig_type.update_yaxes(range=[0, type_data['ä¸­ä½æ•°æœˆè–ª'].max() * 1.15])
        st.plotly_chart(fig_type, use_container_width=True)

    # ç¬¬ä¸€çº§ï¼šæ ¸å¿ƒæ¦‚è¦
    st.markdown("æ ¸å¿ƒç»“è®ºï¼šå…¬å¸è§„æ¨¡ä¸è–ªé…¬æ°´å¹³æ•´ä½“å‘ˆæ­£ç›¸å…³ï¼›åœ¨æ€§è´¨ä¸Šï¼Œä¸Šå¸‚å…¬å¸ä¸å¤–èµ„ä¼ä¸šæä¾›äº†æœ€å…·ç«äº‰åŠ›çš„è–ªé…¬ã€‚")

    # ç¬¬äºŒçº§ï¼šå¯å±•å¼€çš„è¯¦ç»†è§£è¯»
    with st.expander("ç‚¹å‡»æŸ¥çœ‹è¯¦ç»†è§£è¯» ğŸ‘‡"):
        st.markdown("""
        *   **è§„æ¨¡æ•ˆåº”:** ä»â€œå°‘äº15äººâ€çš„åˆåˆ›å›¢é˜Ÿï¼Œåˆ°â€œ10000äººä»¥ä¸Šâ€çš„å·¨å‹ä¼ä¸šï¼Œè–ªé…¬ä¸­ä½æ•°éšç€å…¬å¸è§„æ¨¡çš„æ‰©å¤§è€Œç¨³æ­¥æå‡ï¼Œæ¸…æ™°åœ°è¯æ˜äº†â€œå¤§å‚â€åœ¨è–ªé…¬ä¸Šçš„ä¼˜åŠ¿ã€‚
        *   **æ€§è´¨å·®å¼‚:** `ä¸Šå¸‚å…¬å¸` å’Œ `å¤–èµ„ä¼ä¸š` åœ¨è–ªé…¬ä¸­ä½æ•°ä¸Šå¤„äºç¬¬ä¸€æ¢¯é˜Ÿï¼Œæ˜¯å¸‚åœºçš„â€œè–ªé…¬æ ‡æ†â€ã€‚`å›½æœ‰ä¼ä¸š` å’Œ `åˆèµ„ä¼ä¸š` æä¾›äº†ä¼˜åšä¸”ç¨³å®šçš„æ¬¡çº§é€‰æ‹©ã€‚è€Œ `æ°‘è¥å…¬å¸` ä½œä¸ºæ•°é‡æœ€åºå¤§çš„å¸‚åœºä¸»ä½“ï¼Œå…¶è–ªé…¬ä¸­ä½æ•°æ„æˆäº†æ•´ä¸ªè¡Œä¸šçš„â€œåŸºå‡†çº¿â€ã€‚
        """)

    st.write("---")

    # --- æ¨¡å—äº”ï¼šå²—ä½çƒ­åŠ›å›¾ --
    st.header("5. å…¨å›½å²—ä½å¯†åº¦çƒ­åŠ›å›¾")
    map_data = df_display[['å²—ä½å‘å¸ƒ-lat', 'å²—ä½å‘å¸ƒ-lon']].rename(
        columns={'å²—ä½å‘å¸ƒ-lat': 'lat', 'å²—ä½å‘å¸ƒ-lon': 'lon'})
    map_data = map_data[(map_data['lat'] > 0) & (map_data['lon'] > 0)]
    if not map_data.empty:
        st.pydeck_chart(pdk.Deck(layers=[pdk.Layer('HeatmapLayer', data=map_data, get_position='[lon, lat]')],
                                 initial_view_state=pdk.ViewState(latitude=36, longitude=104, zoom=3.5, pitch=45)))

else:
    # ---------------------------------
    #   æ¨¡å¼äºŒï¼šâ€œæ·±åº¦ä¸‹é’»â€ (å½“æœ‰ç­›é€‰æ—¶)
    # ---------------------------------
    st.success(f"ğŸ” **æ‚¨æ­£åœ¨å¯¹ã€{len(df_display)}ã€‘ä¸ªç‰¹å®šå²—ä½è¿›è¡Œã€æ·±åº¦ä¸‹é’»ã€‘åˆ†æã€‚**")

    # --- ä¸‹é’»åˆ†æä¸€ï¼šè¯¥ç¾¤ä½“çš„çƒ­é—¨å²—ä½ ---
    st.header("1. è¯¥ç¾¤ä½“çš„çƒ­é—¨å²—ä½ç±»åˆ«")
    hot_data, _ = prepare_category_data(df_display,cache_key=len(df_display))
    # ç”¨â€œé“¾å¼è°ƒç”¨â€ï¼Œå°†æ‰€æœ‰é…ç½®å†™åœ¨ä¸€èµ·
    fig_hot_drill = (px.bar(
        hot_data, x='å²—ä½æ•°é‡', y='æ£€ç´¢äºŒçº§èŒä½ç±»åˆ«', text='å²—ä½æ•°é‡',
        orientation='h', template='plotly_white', title='è¯¥ç¾¤ä½“çƒ­é—¨å²—ä½ TOP 15',
        labels={'æ£€ç´¢äºŒçº§èŒä½ç±»åˆ«': 'èŒä½ç±»åˆ«'}
    ).update_layout(
        title_x=0.5, xaxis_title='å²—ä½æ•°é‡ (ä¸ª)', yaxis_title="èŒä½ç±»åˆ«",
        yaxis={'categoryorder': 'total ascending'},
        margin=dict(l=150)  # å¢åŠ å·¦è¾¹è·
    ).update_traces(
        textposition='outside'
    ))
    st.plotly_chart(fig_hot_drill, use_container_width=True)

    # --- ä¸‹é’»åˆ†æäºŒï¼šè¯¥ç¾¤ä½“çš„è–ªèµ„åˆ†å¸ƒ ---
    st.header("2. è¯¥ç¾¤ä½“çš„è–ªèµ„åˆ†å¸ƒ")
    col_hist, col_box = st.columns(2)
    with col_hist:
        st.subheader("è–ªèµ„åˆ†å¸ƒç›´æ–¹å›¾")
        fig_hist_drill = px.histogram(df_display, x="æœˆè–ª", title="è–ªèµ„åˆ†å¸ƒ", nbins=50)
        fig_hist_drill.update_layout(title_x=0.5)
        st.plotly_chart(fig_hist_drill, use_container_width=True)
    with col_box:
        st.subheader("è–ªèµ„åˆ†å¸ƒç®±å½¢å›¾")
        fig_box_drill = px.box(df_display, y="æœˆè–ª", points="all", title="è–ªèµ„åˆ†å¸ƒ")

        fig_box_drill.update_yaxes(type="log")
        fig_box_drill.update_layout(title_x=0.5)
        st.plotly_chart(fig_box_drill, use_container_width=True)
    st.markdown(
        "> **è§£è¯»:** ç›´æ–¹å›¾çš„â€œå±±å³°â€æ­ç¤ºäº†è–ªèµ„çš„**ä¸»ä½“**é›†ä¸­åŒºé—´ï¼›è€Œç®±å½¢å›¾ï¼ˆå·²å¯ç”¨å¯¹æ•°åæ ‡è½´ï¼‰åˆ™æ›´æ¸…æ™°åœ°å±•ç¤ºäº†**ä¸­ä½æ•°**ã€**æ ¸å¿ƒ50%**çš„èŒƒå›´ã€ä»¥åŠ**ç¦»ç¾¤å€¼**çš„åˆ†å¸ƒæƒ…å†µã€‚")

    st.write("---")

    # --- ä¸‹é’»åˆ†æä¸‰ï¼šå²—ä½çƒ­åŠ›å›¾ ---
    st.header("3. è¯¥ç¾¤ä½“çš„å²—ä½åœ°ç†åˆ†å¸ƒ")

    map_data_drill = df_display[['å²—ä½å‘å¸ƒ-lat', 'å²—ä½å‘å¸ƒ-lon', 'æ£€ç´¢åŸå¸‚']].copy()
    map_data_drill.rename(columns={'å²—ä½å‘å¸ƒ-lat': 'lat', 'å²—ä½å‘å¸ƒ-lon': 'lon'}, inplace=True)
    map_data_drill = map_data_drill[(map_data_drill['lat'] > 0) & (map_data_drill['lon'] > 0)]

    if not map_data_drill.empty:
        #

        # 1. è·å–ç”¨æˆ·ç­›é€‰äº†å¤šå°‘ä¸ªä¸åŒçš„åŸå¸‚
        num_selected_cities = map_data_drill['æ£€ç´¢åŸå¸‚'].nunique()

        # 2. æ ¹æ®åŸå¸‚æ•°é‡ï¼Œå†³å®šåœ°å›¾çš„ä¸­å¿ƒç‚¹å’Œç¼©æ”¾ç­‰çº§
        if num_selected_cities > 1:
            # å¦‚æœé€‰æ‹©äº†å¤šä¸ªåŸå¸‚ï¼Œä½¿ç”¨å…¨ä¸­å›½çš„å®è§‚è§†è§’
            initial_view_state_drill = pdk.ViewState(
                latitude=36,
                longitude=104,
                zoom=3.5,
                pitch=45
            )
        else:
            # å¦‚æœåªé€‰æ‹©äº†ä¸€ä¸ªåŸå¸‚å°±èšç„¦äºè¯¥åŸå¸‚çš„ä¸­å¿ƒ
            initial_view_state_drill = pdk.ViewState(
                latitude=map_data_drill['lat'].mean(),
                longitude=map_data_drill['lon'].mean(),
                zoom=9,
                pitch=50
            )

        # 3. æ¸²æŸ“åœ°å›¾
        heatmap_layer_drill = pdk.Layer('HeatmapLayer', data=map_data_drill, get_position='[lon, lat]', opacity=0.8)
        r_drill = pdk.Deck(layers=[heatmap_layer_drill], initial_view_state=initial_view_state_drill, map_style='light')
        st.pydeck_chart(r_drill)
    else:
        st.warning("è¯¥ç­›é€‰æ¡ä»¶ä¸‹ï¼Œæ— æœ‰æ•ˆçš„åœ°ç†ä½ç½®æ•°æ®ã€‚")

    st.write("---")

    # --- ä¸‹é’»åˆ†æå››ï¼šæŠ€èƒ½ä¸ç¦åˆ©ç”»åƒ ---
    st.header("4. å²—ä½ç”»åƒè¯äº‘ (å¯äºŒæ¬¡ä¸‹é’»)")
    st.markdown("> **è¯´æ˜:** æ‚¨å¯ä»¥å…ˆé€‰æ‹©ä¸€ä¸ª**å²—ä½è§’è‰²**ï¼Œå†è¿›ä¸€æ­¥é€‰æ‹©ä¸€ä¸ª**æ ¸å¿ƒæŠ€æœ¯**ï¼Œè¿›è¡Œç²¾å‡†ç”»åƒã€‚")
    # å®šä¹‰ä¸¤ä¸ªç‹¬ç«‹çš„é€‰é¡¹å­—å…¸
    ROLE_OPTIONS = {
        "ğŸ‘‰ æŸ¥çœ‹ç­›é€‰ç¾¤ä½“çš„æ•´ä½“ç”»åƒ": None,
        "åç«¯å¼€å‘": "åç«¯|Java|Python|Go|PHP|C++",
        "å‰ç«¯å¼€å‘": "å‰ç«¯|Vue|React|Web",
        "äººå·¥æ™ºèƒ½": "ç®—æ³•|AI|æœºå™¨å­¦ä¹ |æ·±åº¦å­¦ä¹ |NLP",
        "æ•°æ®åˆ†æ": "æ•°æ®åˆ†æ|BI|æ•°æ®æŒ–æ˜",
        "æµ‹è¯•å¼€å‘": "æµ‹è¯•|æµ‹å¼€|QA",
    }
    TECH_OPTIONS = {
        "ğŸ‘‰ ä¸é™ç‰¹å®šæŠ€æœ¯": None,
        "Java": "Java(?!Script)",
        "Python": "Python",
        "C++": "C\+\+",
        "Go": "Goè¯­è¨€|Golang",
    }

    # åˆ›å»ºä¸¤ä¸ªç‹¬ç«‹çš„ä¸‹æ‹‰é€‰æ‹©å™¨
    col_role, col_tech = st.columns(2)
    with col_role:
        selected_role = st.selectbox(
            label="ç¬¬ä¸€æ­¥ï¼šè¯·é€‰æ‹©ä¸€ä¸ªå²—ä½è§’è‰²",
            options=list(ROLE_OPTIONS.keys()),
            key='drilldown_role_select'  # æ·»åŠ ä¸€ä¸ªå”¯ä¸€çš„keyï¼Œé˜²æ­¢ä¸å…¨å±€å†²çª
        )
    with col_tech:
        selected_tech = st.selectbox(
            label="ç¬¬äºŒæ­¥ï¼šè¯·é€‰æ‹©ä¸€ä¸ªæ ¸å¿ƒæŠ€æœ¯ (å¯é€‰)",
            options=list(TECH_OPTIONS.keys()),
            key='drilldown_tech_select'  # æ·»åŠ ä¸€ä¸ªå”¯ä¸€çš„key
        )

    # åŒå±‚è¿‡æ»¤
    df_for_wordcloud = df_display.copy()
    title_profile = "æ•´ä½“"
    title_parts = []

    if selected_role and ROLE_OPTIONS[selected_role]:
        df_for_wordcloud = df_for_wordcloud[
            df_for_wordcloud['å²—ä½å'].str.contains(ROLE_OPTIONS[selected_role], case=False, na=False)
        ]
        title_parts.append(selected_role)

    if selected_tech and TECH_OPTIONS[selected_tech]:
        search_tech = TECH_OPTIONS[selected_tech]
        df_for_wordcloud = df_for_wordcloud[
            df_for_wordcloud['å²—ä½å'].str.contains(search_tech, case=False, na=False) |
            df_for_wordcloud['å²—ä½æè¿°'].str.contains(search_tech, case=False, na=False)
            ]
        title_parts.append(selected_tech)

    if title_parts:
        title_profile = " & ".join(title_parts)
    if df_for_wordcloud.empty:
        st.warning(f"åœ¨å½“å‰ç­›é€‰æ¡ä»¶ä¸‹ï¼Œæ²¡æœ‰æ‰¾åˆ°ä¸â€œ{title_profile}â€ç›¸å…³çš„å²—ä½ã€‚")
    else:
        col_skill, col_benefit = st.columns(2)
        with col_skill:
            st.subheader(f"{title_profile} - æ ¸å¿ƒæŠ€æœ¯ç”»åƒ")
            # è°ƒç”¨å‡½æ•°æ—¶ï¼ŒæŠŠåŠ¨æ€ç”Ÿæˆçš„ title_profile ä½œä¸º cache_key ä¼ è¿›å»
            fig_skill = generate_wordcloud_image(
                df_for_wordcloud,
                'å²—ä½æè¿°',
                use_stopwords=True,
                cache_key=f"skill_{title_profile}"  # ä¾‹å¦‚ "skill_åç«¯å¼€å‘ & Java"
            )
            if fig_skill:
                st.pyplot(fig_skill)
            else:
                st.warning("æ— è¶³å¤Ÿæ•°æ®ç”Ÿæˆæ ¸å¿ƒæŠ€æœ¯è¯äº‘ã€‚")

        with col_benefit:
            st.subheader(f"{title_profile} - ç¦åˆ©å¾…é‡ç”»åƒ")
            fig_benefit = generate_wordcloud_image(
                df_for_wordcloud,
                'å²—ä½ç¦åˆ©å¾…é‡',
                use_stopwords=False,
                cache_key=f"benefit_{title_profile}"
            )
            if fig_benefit:
                st.pyplot(fig_benefit)
            else:
                st.warning("æ— è¶³å¤Ÿæ•°æ®ç”Ÿæˆç¦åˆ©å¾…é‡è¯äº‘ã€‚")
    st.write("---")


 # --- ä¸‹é’»åˆ†æäº”ï¼šæ•°æ®è¯¦æƒ…æµè§ˆå™¨ ---
    st.header("5. æ•°æ®è¯¦æƒ…æµè§ˆå™¨")
    with st.expander("ç‚¹å‡»å±•å¼€/æŠ˜å ï¼ŒæŸ¥çœ‹å½“å‰ç­›é€‰æ¡ä»¶ä¸‹çš„å…·ä½“å²—ä½æ•°æ® ğŸ‘‡"):
        st.dataframe(df_display[['å²—ä½å', 'å…¬å¸åç§°', 'æœˆè–ª', 'å­¦å†', 'ç»éªŒæ ‡ç­¾', 'æ£€ç´¢åŸå¸‚', 'å²—ä½ç¦åˆ©å¾…é‡']])



